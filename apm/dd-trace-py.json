{
  "url": "https://api.github.com/repos/DataDog/dd-trace-py/releases/271587028",
  "assets_url": "https://api.github.com/repos/DataDog/dd-trace-py/releases/271587028/assets",
  "upload_url": "https://uploads.github.com/repos/DataDog/dd-trace-py/releases/271587028/assets{?name,label}",
  "html_url": "https://github.com/DataDog/dd-trace-py/releases/tag/v4.1.0",
  "id": 271587028,
  "author": {
    "login": "emmettbutler",
    "id": 723615,
    "node_id": "MDQ6VXNlcjcyMzYxNQ==",
    "avatar_url": "https://avatars.githubusercontent.com/u/723615?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/emmettbutler",
    "html_url": "https://github.com/emmettbutler",
    "followers_url": "https://api.github.com/users/emmettbutler/followers",
    "following_url": "https://api.github.com/users/emmettbutler/following{/other_user}",
    "gists_url": "https://api.github.com/users/emmettbutler/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/emmettbutler/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/emmettbutler/subscriptions",
    "organizations_url": "https://api.github.com/users/emmettbutler/orgs",
    "repos_url": "https://api.github.com/users/emmettbutler/repos",
    "events_url": "https://api.github.com/users/emmettbutler/events{/privacy}",
    "received_events_url": "https://api.github.com/users/emmettbutler/received_events",
    "type": "User",
    "user_view_type": "public",
    "site_admin": false
  },
  "node_id": "RE_kwDOA6uE5s4QMBbU",
  "tag_name": "v4.1.0",
  "target_commitish": "4.1",
  "name": "4.1.0",
  "draft": false,
  "immutable": false,
  "prerelease": false,
  "created_at": "2025-12-18T21:38:20Z",
  "updated_at": "2025-12-18T21:39:30Z",
  "published_at": "2025-12-18T21:39:30Z",
  "assets": [

  ],
  "tarball_url": "https://api.github.com/repos/DataDog/dd-trace-py/tarball/v4.1.0",
  "zipball_url": "https://api.github.com/repos/DataDog/dd-trace-py/zipball/v4.1.0",
  "body": "Estimated end-of-life date, accurate to within three months: 05-2027\r\nSee [the support level definitions](https://docs.datadoghq.com/tracing/trace_collection/compatibility/python/#releases) for more information.\r\n\r\n### Upgrade Notes\r\n\r\n- LLM Observability\r\n  - Experiments spans now contain metadata from the dataset record.\r\n  - Experiments spans' input, output, expected_output fields are now emitted as is so that if data in any of the columns are objects, they can be searchable in Datadog.\r\n  - Experiments spans and children spans are now tagged with human readable names to allow better analysis of experiments data. New tags added are: `dataset_name`, `project_name`, `project_id`, `experiment_name`.\r\n- tornado\r\n  - Updated minimum supported version to v6.1+.\r\n\r\n### Deprecation Notes\r\n\r\n- tornado\r\n  - Deprecated support for Tornado versions older than v6.1. Use Tornado v6.1 or later.\r\n- LLM Observability\r\n  - The `ExperimentResult` class' `rows` and `summary_evaluations` attributes are deprecated and will be removed in the next major release. `ExperimentResult.rows/summary_evaluations` attributes will only store the results of the first run iteration for multi-run experiments. Use the `ExperimentResult.runs` attribute instead to access experiment results and summary evaluations.\r\n\r\n### New Features\r\n\r\n- profiling\r\n  - Add support for `threading.BoundedSemaphore` locking type profiling in Python. The implementation follows the same approach as `threading.Semaphore`, properly handling internal lock detection to prevent double-counting of the underlying `threading.Lock` object.\r\n  - Add support for `threading.Semaphore` locking type profiling in Python. The Lock profiler now detects and marks \"internal\" Lock objects, i.e. those that are part of implementation of higher-level locking types. One example of such higher-level primitive is `threading.Semaphore`, which is implemented with `threading.Condition`, which itself uses `threading.Lock` internally. Marking internal lock as \"internal\" will prevent it from being sampled, ensuring that the high-level (e.g. Semaphore) sample is processed.\r\n  - This adds support for Python 3.14 in the Continuous Profiler.\r\n  - This adds the `process_id` tag to profiles. The value of this tag is the current process ID (PID).\r\n  - The stack sampler supports async generators and `asyncio.wait`.\r\n  - Shows fully qualified name of functions using `codeobject.co_qualname` in memory profiler and lock profiler flamegraphs for Python 3.11+. Stack profiler has already been using this. This aligns the user experience across different profile types.\r\n  - This introduces tracking for the `asyncio.as_completed` util in the Profiler.\r\n  - This introduces tracking for `asyncio.wait` in the Profiler. This makes it possible to track dependencies between Tasks/Coroutines that await/are awaited through `asyncio.wait`.\r\n- AAP\r\n  - attach Application and API Protection findings on API Gateway inferred spans to enable AppSec API Catalog coverage of lambda functions\r\n  - This introduces proper support for API10 for redirected requests on urllib3\r\n- anthropic\r\n  - Adds support for the Anthropic Beta client API (`client.beta.messages.create()` and `client.beta.messages.stream()`). This feature requires Anthropic client version 0.37.0 or higher.\r\n- aiokafka\r\n  - Adds DSM instrumentation support.\r\n  - Adds instrumentation support for `aiokafka>=0.9.0`. See the `aiokafka<https://ddtrace.readthedocs.io/en/stable/integrations.html#aiokafka>` documentation for more information.\r\n- Added support for uWSGI with gevent when threads are also patched. The use of the keyword argument `thread=False` is no longer required when performing monkey-patching with gevent via `gevent.monkey.patch_all`.\r\n- LLM Observability\r\n  - Reasoning token counts are now captured from Google GenAI responses.\r\n  - The OpenAI integration now captures prompt metadata (id, version, variables, and chat template) for reusable prompts when using the `responses` endpoint (available in OpenAI SDK >= 1.87.0).\r\n  - Experiments can now be run multiple times by using the optional `runs` argument, to assess the true performance of an experiment in the face of the non determinism of LLMs. Use the new `ExperimentResult` class' `runs` attribute to access the results and summary evaluations by run iteration.\r\n  - Non-root experiment spans are now tagged with experiment ID, run ID, and run iteration tags.\r\n  - Adds additional tags to MCP client session and tool call spans to power LLM Observability MCP tool call features.\r\n  - Reasoning token counts are now captured from OpenAI and OpenAI Agents responses.\r\n  - openai\r\n    - This introduces support for capturing server-side MCP tool calls invoked via the OpenAI Responses API as a separate span.\r\n- langchain\r\n  - Adds support for tracing `RunnableLambda` instances.\r\n- mcp\r\n  - Marks client mcp tool call spans as errors when the corresponding server tool call errored\r\n- Crashtracker\r\n  - This introduces a fallback to capture runtime stack frames when Python's `_Py_DumpTracebackThreads` function is not available.\r\n- ASGI\r\n  - Enable context propagation between websocket message spans.\r\n\r\n### Bug Fixes\r\n\r\n- avro\r\n  - Fixes an issue where Avro instrumentation does not return method results when DSM is enabled.\r\n- crashtracker\r\n  - Fixes missing env variables inheritance for receiver process.\r\n- dynamic instrumentation\r\n  - uploading snapshots now retries on all HTTP error codes.\r\n- exception replay\r\n  - fixed the order in which frames are captured to ensure that the values of frames close to the point where the initial exception was thrown are always attached to the relevant spans.\r\n  - fixed an infinite loop that could cause memory leaks when capturing exceptions, and improved overall speed and memory performance.\r\n  - ensure exception information is captured when exceptions are raised by the GraphQL client library.\r\n- Code Security\r\n  - Fixes critical memory safety issue in IAST when used with forked worker processes (MCP servers with Gunicorn and Uvicorn). Workers previously crashed with segmentation faults due to stale PyObject pointers in native taint maps after fork.\r\n- openai\r\n  - Resolves an issue where instantiating an OpenAI client with a non-string API key resulted in parsing issues.\r\n- tracing\r\n  - Fixed a potential `IndexError` in partial flush when the finished span counter was out of sync with actual finished spans.\r\n  - `DD_TRACE_PARTIAL_FLUSH_MIN_SPANS` values less than 1 now default to 1 with a warning.\r\n  - Resolves a potential deadlock when forking.\r\n  - CI Visibility: Ensure the http connection is correctly reset in all error scenarios.\r\n- ray\r\n  - This fix resolves an issue where Ray jobs that did not explicitly call `ray.init()` at the top of their scripts were not properly instrumented, resulting in incomplete traces. To ensure full tracing capabilities, use `ddtrace-run` when starting your Ray cluster: `DD_PATCH_MODULES=\"ray:true,aiohttp:false,grpc:false,requests:false\" ddtrace-run ray start --head`.\r\n- AAP\r\n  - This fix resolves an issue where the appsec layer was not compatible anymore with the lambda/serverless version of the tracer.\r\n- lib-injection\r\n  - do not inject into the `gsutil` tool\r\n- LLM Observability\r\n  - Fixes an issue where `LLMObs.export_span()` would raise when LLMObs is disabled.\r\n  - Resolves an issue where `self` was being annotated as an input parameter using LLM Observability function decorators.\r\n  - This fix resolves an issue where `LLMObs.annotation_context()` properties (tags, prompt, and name) were not applied to subsequent LLM operations within the same context block. This occurred when multiple sequential operations (such as Langchain batch calls with structured outputs) were performed, causing only the first operation to receive the annotations.\r\n  - This fix resolves an issue where evaluation-metric labels containing dots could be interpreted as nested objects by adding validation that rejects such labels and provides a clear error message instructing users to use alternative naming conventions.\r\n  - Fixes an issue where the Google ADK integration would throw an `AttributeError` when trying to access the `name` or `description` attributes of a tool.\r\n- opentelemetry\r\n  - Fixed spans going unsampled when using `opentelemetry.trace.get_current_span()` or `NonRecordingSpan`. Spans are now kept and appear in the UI unless explicitly dropped by the Agent or sampling rules.\r\n- profiling\r\n  - This fix resolves a critical issue where the Lock Profiler generated release samples for non-sampled lock acquires, resulting in inflated or negative (when integer overflows) lock hold times (e.g., \"3.24k days per minute\", \"-970 days per minute\"). This affected virtually all customers using sampling rates \\< 100% (which should be the majority).\r\n  - This fix prevents a use-after-free crash from the memory profiler on Python version 3.10 and 3.11. The previous attempt to fix this bug itself had a bug, which this fix addresses.\r\n  - improve reliability when parsing an empty span.\r\n  - Fixes a segmentation fault caused by accessing `frame.f_locals` while trying to retrieve class name of a `PyFrameObject`.\r\n  - This fix improves the detection of on-CPU asyncio Tasks. Previously, the Profiler would only consider a Task as running if its coroutine was running. The Profiler now recursively checks if any coroutine in the await chain of the Task's coroutine is running.\r\n  - This fix makes stack sampling more accurate for on-CPU asyncio Tasks.\r\n  - This fix resolves a race condition leading to incorrect stacks being reported for asyncio parent/child Tasks (e.g. when using `asyncio.gather`).\r\n  - This fix resolves a possible crash coming from the experimental \"fast memory copy\" feature of the Stack Sampler. It occurred when the Profiler's signal handlers were replaced by other ones (from the application code).\r\n  - This updates the stack sampler to fix a bug that would lead to OOMs when the sampler read invalid data from the Python process.\r\n  - This fixes a bug where asyncio stacks would only get partial data, with some coroutines not showing.\r\n  - This improves stack unwinding for asyncio workloads running Python 3.13+ by replicating the official PyGen_yf function from CPython 3.13. Previously, the sampler would use the version from an older version of CPython, which could lead to incomplete asyncio stacks.\r\n\r\n### Other Changes\r\n\r\n- Code Origin for Spans\r\n  - Outgoing requests are no longer included with code origin for spans.\r\n- profiling\r\n  - Moves echion, the Python stack sampler, to the ddtrace-py repository.\r\n  - Store memalloc samples as native objects, avoiding calls into the cpython internal.\r\n"
}
