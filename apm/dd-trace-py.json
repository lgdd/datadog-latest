{
  "url": "https://api.github.com/repos/DataDog/dd-trace-py/releases/263788159",
  "assets_url": "https://api.github.com/repos/DataDog/dd-trace-py/releases/263788159/assets",
  "upload_url": "https://uploads.github.com/repos/DataDog/dd-trace-py/releases/263788159/assets{?name,label}",
  "html_url": "https://github.com/DataDog/dd-trace-py/releases/tag/v4.0.0",
  "id": 263788159,
  "author": {
    "login": "emmettbutler",
    "id": 723615,
    "node_id": "MDQ6VXNlcjcyMzYxNQ==",
    "avatar_url": "https://avatars.githubusercontent.com/u/723615?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/emmettbutler",
    "html_url": "https://github.com/emmettbutler",
    "followers_url": "https://api.github.com/users/emmettbutler/followers",
    "following_url": "https://api.github.com/users/emmettbutler/following{/other_user}",
    "gists_url": "https://api.github.com/users/emmettbutler/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/emmettbutler/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/emmettbutler/subscriptions",
    "organizations_url": "https://api.github.com/users/emmettbutler/orgs",
    "repos_url": "https://api.github.com/users/emmettbutler/repos",
    "events_url": "https://api.github.com/users/emmettbutler/events{/privacy}",
    "received_events_url": "https://api.github.com/users/emmettbutler/received_events",
    "type": "User",
    "user_view_type": "public",
    "site_admin": false
  },
  "node_id": "RE_kwDOA6uE5s4PuRZ_",
  "tag_name": "v4.0.0",
  "target_commitish": "4.0.0",
  "name": "4.0.0",
  "draft": false,
  "immutable": false,
  "prerelease": false,
  "created_at": "2025-11-14T20:18:05Z",
  "updated_at": "2025-11-19T21:10:40Z",
  "published_at": "2025-11-19T21:10:40Z",
  "assets": [

  ],
  "tarball_url": "https://api.github.com/repos/DataDog/dd-trace-py/tarball/v4.0.0",
  "zipball_url": "https://api.github.com/repos/DataDog/dd-trace-py/zipball/v4.0.0",
  "body": "Estimated end-of-life date, accurate to within three months: 05-2027\r\nSee [the support level definitions](https://docs.datadoghq.com/tracing/trace_collection/compatibility/python/#releases) for more information.\r\n\r\nThis is a major-version release that contains many backwards-incompatible changes to public APIs. To find which of these your code relies on, follow the \"deprecation warnings\" instructions [here](https://ddtrace.readthedocs.io/en/stable/upgrading.html#deprecation-warnings).\r\n\r\ndd-trace-py now includes an OpenFeature provider implementation, enabling feature flag evaluation through the OpenFeature API.\r\n\r\n_This integration is under active design and development. Functionality and APIs are experimental and may change without notice. For more information, see the Datadog documentation at <https://docs.datadoghq.com/feature_flags/#overview>_\r\n\r\n\r\n### Breaking Changes\r\n\r\n- Support for ddtrace with Python 3.8 is removed after being deprecated in the 3.0 release line. Use ddtrace 4.x with Python 3.9 or newer.\r\n- 32-bit linux is no longer supported. Please contact us if this blocks upgrading dd-trace-py.\r\n- mongoengine\r\n  - Drops support for the `ddtrace.Pin` object with mongoengine. With this change, the ddtrace library no longer directly supports mongoengine. Mongoengine will be supported through the `pymongo` integration.\r\n- CI Visibility\r\n  - Removed deprecated entry points for the `pytest_benchmark` and `pytest_bdd` integrations. These plugins are now supported by the regular `pytest` integration.\r\n- dynamic instrumentation\r\n  - removed the deprecated `DD_DYNAMIC_INSTRUMENTATION_UPLOAD_FLUSH_INTERVAL` variable.\r\n- exception replay\r\n  - removed the deprecated `DD_EXCEPTION_DEBUGGING_ENABLED` variable.\r\n- tracing\r\n  - Deprecated methods have been removed\r\n    - `Span.set_tag_str` has been removed, use `Span.set_tag` instead.\r\n    - `Span.set_struct_tag` has been removed.\r\n    - `Span.get_struct_tag` has been removed.\r\n    - `Span._pprint` has been removed\r\n    - `Span.finished` setter was removed, please use `Span.finish()` method instead.\r\n    - `Tracer.on_start_span` method has been removed.\r\n    - `Tracer.deregister_on_start_span` method has been removed.\r\n    - `ddtrace.trace.Pin` has been removed.\r\n    - `Span.finish_with_ancestors` was removed with no replacement.\r\n  - Some methods have had their type signatures changed\r\n    - `Span.set_tag` typing is now `set_tag(key: str, value: Optional[str] = None) -> None`\r\n    - `Span.get_tag` typing is now `get_tag(key: str) -> Optional[str]`\r\n    - `Span.set_tags` typing is now `set_tags(tags: dict[str, str]) -> None`\r\n    - `Span.get_tags` typing is now `get_tags() -> dict[str, str]`\r\n    - `Span.set_metric` typing is now `set_metric(key: str, value: int | float) -> None`\r\n    - `Span.get_metric` typing is now `get_metric(key: str) -> Optional[int | float]`\r\n    - `Span.set_metrics` typing is now `set_metrics(metrics: Dict[str, int | float]) -> None`\r\n    - `Span.get_metrics` typing is now `get_metrics() -> dict[str, int | float]`\r\n  - `Span.record_exception`'s `timestamp` and `escaped` parameters are removed\r\n- LLM Observability\r\n  - manual instrumentation methods, including `LLMObs.annotate()`, `LLMObs.export_span()`, `LLMObs.submit_evaluation()`, `LLMObs.inject_distributed_headers()`, and `LLMObs.activate_distributed_headers()` now raise exceptions instead of logging. LLM Observability auto-instrumentation is not affected.\r\n  - `LLMObs.submit_evaluation_for()` has been removed. Please use `LLMObs.submit_evaluation()` instead for submitting evaluations. To migrate:\r\n    - `LLMObs.submit_evaluation_for(...)` users: rename to `LLMObs.submit_evaluation(...)`\r\n    - `LLMObs.submit_evaluation_for(...)` users: rename the `span_context` argument to `span`, i.e. `LLMObs.submit_evaluation(span_context={\"span_id\": ..., \"trace_id\": ...}, ...)` to `LLMObs.submit_evaluation(span={\"span_id\": ..., \"trace_id\": ...}, ...)`\r\n- profiling\r\n  - this updates echion (the Python stack sampler) to the latest version, which introduces an experimental faster memory copy function.\r\n  - The V1 stack profiler is removed. V2 has been enabled by default since v2.20.0. `DD_PROFILING_STACK_V2_ENABLED` is now removed.\r\n- freezegun\r\n  - The deprecated `freezegun` integration is now removed.\r\n- opentracer\r\n  - This change removes the deprecated `opentracer` package\r\n- aioredis\r\n  - The aioredis integration has been removed.\r\n- google_generativeai\r\n  - The `google_generativeai` integration has been removed as the `google_generativeai` library has reached end-of-life.\r\n  As an alternative, you can use the recommended `google_genai` library and corresponding integration instead.\r\n- openai\r\n  - Streamed chat/completions will no longer have token counts computed using the `tiktoken` library, and instead\r\n  will default to having their token counts estimated if not explicitly provided in the OpenAI response object. To guarantee accurate streamed token metrics, set `stream_options={\"include_usage\": True}` in the OpenAI request.\r\n- django\r\n  - This upgrades the default tracing behavior to enable minimal tracing mode by default (``DD_DJANGO_TRACING_MINIMAL`` now defaults to ``true``). Django ORM, cache, and template instrumentation are disabled by default to eliminate duplicate span creation since library integrations for database drivers (psycopg, MySQLdb, sqlite3), cache clients (redis, memcached), template renderers (Jinja2), and other supported libraries continue to be traced. This reduces performance overhead by removing redundant Django-layer instrumentation. To restore all Django instrumentation, set ``DD_DJANGO_TRACING_MINIMAL=false``, or enable individual features using ``DD_DJANGO_INSTRUMENT_DATABASES=true``, ``DD_DJANGO_INSTRUMENT_CACHES=true``, and ``DD_DJANGO_INSTRUMENT_TEMPLATES=true``.\r\n  - When ``DD_DJANGO_INSTRUMENT_DATABASES=true`` (default ``false``), database instrumentation now merges Django-specific tags into database driver spans created by supported integrations (psycopg, sqlite3, MySQLdb, etc.) instead of creating duplicate Django database spans. If the database cursor is not already wrapped by a supported integration, Django wraps it and creates a span. This change reduces overhead and duplicate spans while preserving visibility into database operations.\r\n- Other\r\n  - This change removes the `ddtrace.settings` package. Environment variables should be used to adjust settings.\r\n  - This change removes the deprecated non_active_span parameter to `HttpPropagator.inject`\r\n  - This change removes the deprecated environment variable `DEFAULT_RUNTIME_METRICS_INTERVAL`.\r\n\r\n### Deprecation Notes\r\n\r\n- Support for ddtrace with Python 3.9 is deprecated after Python 3.9 reached its end-of-life.\r\n\r\n### New Features\r\n\r\n- AAP\r\n  - This introduces security response id for easy identification of blocking responses.\r\n  - API Security schema collection is now supported in AWS Lambda behind an Application Load Balancer or the Lambda Function URL service where the endpoint cannot be reliably known. API Security reuses the endpoint inferred by the trace resource renaming feature or recomputes it when it is not available to perform sampling instead.\r\n  - AppSec instrumentation for downstream request is now enabled by default for `urllib3` and `requests`. It does not require enabling APM instrumentation for `urllib3` anymore.\r\n- profiling\r\n  - Add support for `threading.RLock` (reentrant lock) profiling. The Lock profiler now tracks both `threading.Lock` and `threading.RLock` usage, providing comprehensive lock contention visibility for Python applications.\r\n- LLM Observability\r\n  - Previous dataset versions can be optionally pulled by passing the `version` argument to `LLMObs.pull_dataset`\r\n  - Datasets have new properties `version` and `latest_version` to provide information on the version of the dataset that is being worked with and the latest global version of the dataset, respectively\r\n\r\n### Bug Fixes\r\n\r\n- CI Visibility\r\n  - This fix resolves an issue where repo tags would be fetched while unshallowing to extract commit metadata, causing performance issues for repos with a large number of tags.\r\n  - This fix resolves performance issue affecting coverage collection for Python 3.12+\r\n- data_streams\r\n  - This fix resolves an issue where payload size statistics were not being sent to the backend for Data Streams Monitoring (DSM).\r\n- core\r\n  - This fix resolves an issue where forksafe locks used patched threading primitives from the profiling module, causing performance issues. The forksafe module now uses unpatched threading primitives (`Lock`, `RLock`, `Event`).\r\n- LLM Observability\r\n  - add support for `HTTPS_PROXY`.\r\n  - Resolves an issue in the bedrock integration where invoking cohere rerank models would result in missing spans due to output formatting index errors.\r\n  - Corrected the description of the `assessment` argument in `submit_evaluation()`.\r\n  - Resolves an issue where the `langchain` integration would incorrectly mark Azure OpenAI calls as duplicate llm operations even if the `openai` integration was enabled.\r\n- Error Tracking\r\n  - Modifies the way exception events are stored such that the exception id is stored instead of the exception object, to prevent TypeErrors with custom exception objects.\r\n- dynamic instrumentation\r\n  - fix issue with line probes matching the wrong source file when multiple source files from different Python path entries share the same name.\r\n- profiling\r\n  - This fix resolves an issue where importing the profiler module after an asyncio Event Loop had been started would make the Profiler blind to the existing Event Loop and its Tasks.\r\n  - `DD_PROFILING_API_TIMEOUT` doesn't have any effect, and is marked to be removed in upcoming 4.0 release. New environment variable `DD_PROFILING_API_TIMEOUT_MS` is introduced to configure timeout for uploading profiles to the backend. The default value is 10000 ms (10 seconds)\r\n  - Upgrades echion to resolve an issue where stack profiler can allocate a large amount of memory unnecessarily. Resolves another issue where the profiler can loop infinitely on Python 3.13.\r\n  - This fix resolves an issue where AssertionError exceptions were silently suppressed in the `_acquire` method of the Lock profiler (note: this only occurs when assertions are enabled.)\r\n- kafka\r\n  - This fix resolves an issue where only the first message in a batch was dispatched to Data Streams Monitoring (DSM) when consuming multiple Kafka messages\r\n- langchain\r\n  - This fix resolves an issue where auto instrumented prompt templates incorrectly included a `version` field. The version field is now omitted unless explicitly set by the user.\r\n    `assessment` now refers to whether the evaluation itself passes or fails according to your application, rather than the validity of the evaluation result.\r\n    The `langchain` integration will trace Azure OpenAI spans as workflow spans if there is an equivalent llm span from the `openai` integration.\r\n  - Fixes an issue where streamed responses that end before the first chunk is received would result in an `IndexError`.\r\n- openai\r\n  - This fix resolves an issue where using async iteration with paginated methods (e.g., `async for model in client.models.list()`) caused a `TypeError: 'async for' requires an object with __aiter__ method, got coroutine`. See [issue \\#14574](https://github.com/DataDog/dd-trace-py/issues/14574).\r\n- opentelemetry\r\n  - Fixed circular import when enabling multiple OpenTelemetry signals (metrics + logs) simultaneously.\r\n  - Prevents OpenTelemetry OTLP exporter connections from being traced by ddtrace. ddtrace internal connections (gRPC and HTTP) are now excluded from tracing to prevent circular instrumentation.\r\n- pytest plugin\r\n  - fix for potential `KeyError` exceptions in test runs when gevent is detected within the environment.\r\n- code origin\r\n  - ensure that code location information is added to entry spans when Code Origin is enabled remotely.\r\n- ray\r\n  - This fix resolves an issue where the tracer raised an error when submitting Ray tasks without explicitly calling `ray.init()`.\r\n  - This fix resolves an issue where exceptions raised in Ray child spans were not properly recorded in the trace.\r\n  - This fix stops instrumenting internal Ray actors (those starting with underscore) that were causing excessive noise, and adds `ray.data._internal` to the module denylist.\r\n- IAST\r\n  - Fixed an issue where using weak hashing or cipher algorithms outside of a request context (e.g., during application startup) could raise an unhandled exception. The fix ensures proper error handling when IAST operations are performed without an active request context.\r\n- tracer\r\n  - This fix resolves an issue where an application instrumented by ddtrace could crash at start. Fix compatibility with zope.event==6.0\r\n  - This fix ensures compatibility with wrapt 2.0.0\r\n- logging\r\n  - Fixed ddtrace internal logging when trace-log correlation is disabled. Prevents `ValueError: Formatting field not found in record: 'dd.service'`.\r\n- Other\r\n  - Fix a potential race condition in the tracer.\r\n  - Fix the Python Detector regular expression so it also detects paths ending with only the major version number.\r\n  - Prevent a potential `ResourceWarning` in multiprocess scenarios.\r\n  - Prevent startup failure when a temporary directory is not available.\r\n\r\n### Other Changes\r\n\r\n- profiling\r\n  - This removes the `wrapt` library dependency from the Lock Profiler implementation, improving performance and reducing overhead during lock instrumentation.\r\n"
}
